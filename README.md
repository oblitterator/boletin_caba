
---
"ExtracciÃ³n y Almacenamiento con API del BO de CABA - TP1"
---

# ğŸ“˜ IntroducciÃ³n

El BoletÃ­n Oficial de la Ciudad AutÃ³noma de Buenos Aires es una publicaciÃ³n oficial emitida por el Gobierno porteÃ±o que tiene validez jurÃ­dica. Publica normas, resoluciones y disposiciones administrativas. La Ciudad ofrece una API pÃºblica para acceder a esta informaciÃ³n:  
ğŸ”— https://api-restboletinoficial.buenosaires.gob.ar/

Mediante esta API se puede:
- Obtener el boletÃ­n oficial a partir de una fecha.
- Consultar secciones, normas y anexos publicados.
- Acceder a organismos emisores y reparticiones.

---

# ğŸ¯ Objetivo

El proyecto tiene por finalidad extraer, transformar y almacenar datos del BoletÃ­n Oficial, especialmente normas relacionadas a **licitaciones pÃºblicas**, permitiendo consultas posteriores, enriquecimiento, y anÃ¡lisis textual. El procesamiento incluye:
- Descarga de boletines y normas en crudo.
- ExtracciÃ³n de texto de licitaciones.
- IdentificaciÃ³n de empresas participantes.
- CÃ¡lculo de adjudicaciones.
- Enriquecimiento con organismos emisores.

---

# ğŸ“‚ Estructura del Proyecto

```bash
ğŸ“ TP1_DeltaLake
â”‚
â”œâ”€â”€ ğŸ“‚ data
â”‚   â”œâ”€â”€ ğŸ“‚ bronze
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ boletines
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ normas
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ licitaciones_pdf
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ organismos_emisores
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ reparticiones
â”‚   â”‚   â””â”€â”€ ğŸ“‚ bac_anual
â”‚   â””â”€â”€ ğŸ“‚ silver
â”‚       â”œâ”€â”€ ğŸ“‚ boletines
â”‚       â”œâ”€â”€ ğŸ“‚ licitaciones
â”‚       â”œâ”€â”€ ğŸ“‚ organismos_emisores
â”‚       â””â”€â”€ ğŸ“‚ empresas
â”‚
â”œâ”€â”€ ğŸ“‚ scripts
â”‚   â”œâ”€â”€ boletin_oficial_api.py          # ExtracciÃ³n desde la API
â”‚   â”œâ”€â”€ transformaciones.py             # Limpieza de boletines y normas
â”‚   â”œâ”€â”€ transformaciones_licitaciones.py # Procesamiento de licitaciones
â”‚   â”œâ”€â”€ transformaciones_empresas.py    # NormalizaciÃ³n de empresas
â”‚   â”œâ”€â”€ storage.py                      # Upserts y escritura Delta Lake
â”‚   â”œâ”€â”€ utils_logs.py                   # GestiÃ³n de errores y logs
â”‚
â”œâ”€â”€ ğŸ“‚ logs  # Logs de errores
â”‚
â”œâ”€â”€ almacenamiento.ipynb     # Script principal carga Bronze
â”œâ”€â”€ procesamiento.ipynb      # Script principal carga Silver
â”œâ”€â”€ requirements.txt      # LibrerÃ­as necesarias
â”œâ”€â”€ README.md
```

---

# ğŸš€ Flujo de Trabajo

## ğŸ—ï¸ Almacenamiento (Bronze)

### ğŸ”„ ExtracciÃ³n Incremental
- Arranca desde `fecha_inicio_actualizada` o `FECHA_INICIO` (si se fuerza manualmente).
- Consulta dÃ­a a dÃ­a, verifica duplicados por `numero` o `id_norma`.
- Filtra normas de licitaciones (`subsecciones == "Licitaciones"`), descarga los PDF y extrae su texto.
- Aplica `merge` en Delta Lake para evitar duplicados.
- Particiona por `anio` (boletines) y `tipo_norma` (normas).

### ğŸ“¥ ExtracciÃ³n Full
- Descarga **organismos emisores**, **reparticiones** y **compras anuales (BAC Compras- OCID)**.
- Modo `overwrite`, sin particionado.

### ğŸ›¡ï¸ Control de Errores
- Manejo de `timeouts`, errores HTTP y errores lÃ³gicos del servidor (e.g. XML no encontrado).
- Registro de errores en logs:
  - `logs/log_errores_boletines.csv:` errores al obtener boletines por fecha.
  - `logs/log_errores_normas.csv`: errores al descargar normas en formato PDF.
  - `logs/log_errores_normas_corregidos.csv`: errores que fueron solucionados en una corrida posterior (detectados por ID de norma).
- Se verifica automÃ¡ticamente si un error previamente registrado fue corregido, y en tal caso se mueve al archivo de "corregidos".
---

# ğŸ§  Procesamiento (Silver)

### 1. Carga y DeduplicaciÃ³n
  - Se cargan y deduplican los datos crudos desde Delta Lake Bronze:
  - boletines, normas, licitaciones, organismos, reparticiones y compras OCID.
  - Se prioriza el registro mÃ¡s reciente segÃºn `fecha_extraccion`.

### 2. Limpieza de Licitaciones
- Se extraen `tipo_licitacion`, `etapa_licitacion`, y `codigo_licitacion`.
- Se limpian textos con reglas especÃ­ficas.

### 3. ExtracciÃ³n de Montos
- Regex para identificar montos totales de licitaciÃ³n.
- Beta: Se consideran indistinamente expresiones con `$` o `USD`, y formatos como `1.000.000,00`.

### 4. Match de Empresas
- Se genera un maestro de empresas en base al dataset de BAC compras en el formato OCID por cuit, pais, y razÃ³n social (`df_empresas`).
- Se busca las empresas en el texto de las licitaciones por coincidencia de caracteres (`fuzzywuzzy`).
- Se registra la presencia de empresas por licitaciÃ³n en etapas de preadjudicaciÃ³n, adjudicaciÃ³n y prÃ³rroga.

### 5. CÃ¡lculo de MÃ©tricas por Empresa
- Para cada empresa se calcula:
  - `total_presentaciones`: cantidad de veces que aparece en normas de preadjudicaciÃ³n, adjudicaciÃ³n o prÃ³rrogas de licitaciones.
  - `presentaciones_adjudicacion`: cuÃ¡ntas veces ganÃ³ una licitaciÃ³n.
- Se permite clasificar y rankear segÃºn "Ã©xito".

### 6. Enriquecimiento con InformaciÃ³n de Normas
- Se hace merge con el nÃºmero de boletÃ­n y organismo correspondiente a cada norma para asociar la norma al organismo emisor.

### 7. AnÃ¡lisis por Organismo
- Se genera un resumen por `organismo`:
  - `monto_total_adjudicado`: suma de todos los montos adjudicados.
  - `cantidad_empresas`: cantidad de empresas adjudicadas.

### 8. Enriquecimiento de Empresas
- A cada empresa se le agrega:
  - `organismo_top_adjudicacion`: organismo donde mÃ¡s fue adjudicada.
  - `organismo_top_presencia`: donde mÃ¡s se presentÃ³.

### 9. Almacenamiento Final
- Los datasets enriquecidos se almacenan en Silver en formato Delta Lake  (modo `overwrite`):
  - `boletines`, `licitaciones`, `organismos_emisores`, `empresas`.
---

# ğŸ”§ ModularizaciÃ³n del Proyecto

- `boletin_oficial_api.py`: lÃ³gica de conexiÃ³n, parseo y descarga.
- `storage.py`: inserciÃ³n en Delta Lake (upsert, merge, overwrite).
- `transformaciones.py`: limpieza bÃ¡sica, relleno de nulos, conversiÃ³n de tipos.
- `transformaciones_licitaciones.py`: extracciÃ³n de campos clave, texto y montos.
- `transformaciones_empresas.py`: generaciÃ³n y enriquecimiento de empresas.
- `utils_logs.py`: centraliza guardado de errores en logs.

Los notebooks `almacenamiento.ipynb` y `procesamiento.ipynb` son los puntos de entrada al pipeline.


---
